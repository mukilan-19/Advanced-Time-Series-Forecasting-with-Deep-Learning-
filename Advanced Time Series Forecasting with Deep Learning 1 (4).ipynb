{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f7f138-11ef-4efa-a54e-7e73ccfc7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.24566173553466797\n",
      "Epoch 10 Loss 0.16724969446659088\n",
      "Epoch 20 Loss 0.060859885066747665\n",
      "Epoch 30 Loss 0.03764991834759712\n",
      "\n",
      "ATTENTION LSTM: 0.23225208 0.24459802 31.28059208393097\n",
      "Rolling CV Error: 0.28040326\n",
      "XGBOOST: 0.046675443527244176 0.057820837966432094 6.393091093024528\n",
      "\n",
      "FINAL COMPARISON\n",
      "Model        MAE      RMSE      MAPE\n",
      "AttentionLSTM 0.2323 0.2446 31.28\n",
      "XGBoost       0.0467 0.0578 6.39\n"
     ]
    }
   ],
   "source": [
    "# Advanced Time Series Forecasting with Attention LSTM + Rolling Origin CV + XGBoost\n",
    "# Run in Jupyter by splitting sections into cells OR run as python script\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ===================== 1. DATA GENERATION =====================\n",
    "np.random.seed(42)\n",
    "t = np.arange(1095)\n",
    "series1 = 0.05*t + 15*np.sin(2*np.pi*t/365) + np.random.normal(0,2,1095)\n",
    "series2 = 0.7*series1 + np.random.normal(0,1,1095)\n",
    "series3 = np.cumsum(np.random.normal(0,1,1095))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Sales_Target':series1,\n",
    "    'Foot_Traffic':series2,\n",
    "    'Market_Noise':series3\n",
    "})\n",
    "\n",
    "# ===================== 2. SCALING =====================\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(df.values)\n",
    "\n",
    "SEQ_LEN = 30\n",
    "HORIZON = 7\n",
    "\n",
    "def create_sequences(data, seq_len, horizon):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_len-horizon):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(data[i+seq_len:i+seq_len+horizon,0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data, SEQ_LEN, HORIZON)\n",
    "\n",
    "split = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# ===================== 3. ATTENTION LSTM =====================\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, horizon):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.attn = nn.Linear(hidden_size,1)\n",
    "        self.fc = nn.Linear(hidden_size, horizon)\n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        weights = torch.softmax(self.attn(out),dim=1)\n",
    "        context = torch.sum(weights*out,dim=1)\n",
    "        return self.fc(context)\n",
    "\n",
    "model = AttentionLSTM(3,64,HORIZON)\n",
    "opt = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# ===================== 4. TRAINING =====================\n",
    "for epoch in range(40):\n",
    "    model.train()\n",
    "    pred = model(X_train)\n",
    "    loss = loss_fn(pred,y_train)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch%10==0:\n",
    "        print('Epoch',epoch,'Loss',loss.item())\n",
    "\n",
    "# ===================== 5. METRICS =====================\n",
    "def metrics(true,pred):\n",
    "    mae = mean_absolute_error(true,pred)\n",
    "    rmse = np.sqrt(mean_squared_error(true,pred))\n",
    "    mape = np.mean(np.abs((true-pred)/true))*100\n",
    "    return mae,rmse,mape\n",
    "\n",
    "# ===================== 6. EVALUATE LSTM =====================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test).numpy()\n",
    "true = y_test.numpy()\n",
    "\n",
    "mae_lstm,rmse_lstm,mape_lstm = metrics(true,preds)\n",
    "print('\\nATTENTION LSTM:',mae_lstm,rmse_lstm,mape_lstm)\n",
    "\n",
    "# ===================== 7. ROLLING ORIGIN CV =====================\n",
    "def rolling_cv(model,X,y,start=0.7):\n",
    "    errors=[]\n",
    "    start=int(len(X)*start)\n",
    "    for i in range(start,len(X)-1):\n",
    "        with torch.no_grad():\n",
    "            p=model(X[i:i+1]).numpy()\n",
    "        errors.append(mean_absolute_error(y[i:i+1].numpy(),p))\n",
    "    return np.mean(errors)\n",
    "\n",
    "cv_error = rolling_cv(model,X_test,y_test)\n",
    "print('Rolling CV Error:',cv_error)\n",
    "\n",
    "# ===================== 8. XGBOOST BASELINE =====================\n",
    "X_xgb = X.reshape(len(X),-1)\n",
    "X_train_xgb,X_test_xgb = X_xgb[:split],X_xgb[split:]\n",
    "y_train_xgb,y_test_xgb = y[:split],y[split:]\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=300,max_depth=5,learning_rate=0.05)\n",
    "xgb.fit(X_train_xgb,y_train_xgb)\n",
    "preds_xgb = xgb.predict(X_test_xgb)\n",
    "\n",
    "mae_xgb,rmse_xgb,mape_xgb = metrics(y_test_xgb,preds_xgb)\n",
    "print('XGBOOST:',mae_xgb,rmse_xgb,mape_xgb)\n",
    "\n",
    "# ===================== 9. FINAL COMPARISON =====================\n",
    "print('\\nFINAL COMPARISON')\n",
    "print('Model        MAE      RMSE      MAPE')\n",
    "print(f'AttentionLSTM {mae_lstm:.4f} {rmse_lstm:.4f} {mape_lstm:.2f}')\n",
    "print(f'XGBoost       {mae_xgb:.4f} {rmse_xgb:.4f} {mape_xgb:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
